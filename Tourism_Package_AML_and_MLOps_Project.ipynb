{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klg2JF-oBblG"
   },
   "source": [
    "# Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m0CcOjZ-BblL"
   },
   "source": [
    "## **Business Context**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uyT6Koe7BblM"
   },
   "source": [
    "\"Visit with Us,\" a leading travel company, is revolutionizing the tourism industry by leveraging data-driven strategies to optimize operations and customer engagement. While introducing a new package offering, such as the Wellness Tourism Package, the company faces challenges in targeting the right customers efficiently. The manual approach to identifying potential customers is inconsistent, time-consuming, and prone to errors, leading to missed opportunities and suboptimal campaign performance.\n",
    "\n",
    "To address these issues, the company aims to implement a scalable and automated system that integrates customer data, predicts potential buyers, and enhances decision-making for marketing strategies. By utilizing an MLOps pipeline, the company seeks to achieve seamless integration of data preprocessing, model development, deployment, and CI/CD practices for continuous improvement. This system will ensure efficient targeting of customers, timely updates to the predictive model, and adaptation to evolving customer behaviors, ultimately driving growth and customer satisfaction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zm6bNQOJBblO"
   },
   "source": [
    "## **Objective**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7PYtjk_YBblO"
   },
   "source": [
    "As an MLOps Engineer at \"Visit with Us,\" your responsibility is to design and deploy an MLOps pipeline on GitHub to automate the end-to-end workflow for predicting customer purchases. The primary objective is to build a model that predicts whether a customer will purchase the newly introduced Wellness Tourism Package before contacting them. The pipeline will include data cleaning, preprocessing, transformation, model building, training, evaluation, and deployment, ensuring consistent performance and scalability. By leveraging GitHub Actions for CI/CD integration, the system will enable automated updates, streamline model deployment, and improve operational efficiency. This robust predictive solution will empower policymakers to make data-driven decisions, enhance marketing strategies, and effectively target potential customers, thereby driving customer acquisition and business growth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z8C11AzTBblP"
   },
   "source": [
    "## **Data Description**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DQx3pkaBblP"
   },
   "source": [
    "The dataset contains customer and interaction data that serve as key attributes for predicting the likelihood of purchasing the Wellness Tourism Package. The detailed attributes are:\n",
    "\n",
    "**Customer Details**\n",
    "- **CustomerID:** Unique identifier for each customer.\n",
    "- **ProdTaken:** Target variable indicating whether the customer has purchased a package (0: No, 1: Yes).\n",
    "- **Age:** Age of the customer.\n",
    "- **TypeofContact:** The method by which the customer was contacted (Company Invited or Self Inquiry).\n",
    "- **CityTier:** The city category based on development, population, and living standards (Tier 1 > Tier 2 > Tier 3).\n",
    "- **Occupation:** Customer's occupation (e.g., Salaried, Freelancer).\n",
    "- **Gender:** Gender of the customer (Male, Female).\n",
    "- **NumberOfPersonVisiting:** Total number of people accompanying the customer on the trip.\n",
    "- **PreferredPropertyStar:** Preferred hotel rating by the customer.\n",
    "- **MaritalStatus:** Marital status of the customer (Single, Married, Divorced).\n",
    "- **NumberOfTrips:** Average number of trips the customer takes annually.\n",
    "- **Passport:** Whether the customer holds a valid passport (0: No, 1: Yes).\n",
    "- **OwnCar:** Whether the customer owns a car (0: No, 1: Yes).\n",
    "- **NumberOfChildrenVisiting:** Number of children below age 5 accompanying the customer.\n",
    "- **Designation:** Customer's designation in their current organization.\n",
    "- **MonthlyIncome:** Gross monthly income of the customer.\n",
    "\n",
    "**Customer Interaction Data**\n",
    "- **PitchSatisfactionScore:** Score indicating the customer's satisfaction with the sales pitch.\n",
    "- **ProductPitched:** The type of product pitched to the customer.\n",
    "- **NumberOfFollowups:** Total number of follow-ups by the salesperson after the sales pitch.-\n",
    "- **DurationOfPitch:** Duration of the sales pitch delivered to the customer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0LbSu_p2jYfe"
   },
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "giodc4KknHID"
   },
   "outputs": [],
   "source": [
    "# Create a master folder to keep all files created when executing the below code cells\n",
    "import os\n",
    "os.makedirs(\"tourism_project\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "SUKPoy0EA4jj"
   },
   "outputs": [],
   "source": [
    "# Create a folder for storing the model building files\n",
    "os.makedirs(\"tourism_project/model_building\", exist_ok=True)\n",
    "os.makedirs(\"tourism_project/data\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9DtS3gNDjBbR"
   },
   "source": [
    "## Data Registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "kNUYcTe-xckI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/model_building/data_register.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/model_building/data_register.py\n",
    "from huggingface_hub.utils import RepositoryNotFoundError\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "import os\n",
    "\n",
    "repo_id = \"Retheesh/tourism_package_prediction\"\n",
    "repo_type = \"dataset\"\n",
    "\n",
    "# Initialize API client\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "\n",
    "# Step 1: Check if the space exists\n",
    "try:\n",
    "    api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "    print(f\"Space '{repo_id}' already exists. Using it.\")\n",
    "except RepositoryNotFoundError:\n",
    "    print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
    "    create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
    "    print(f\"Space '{repo_id}' created.\")\n",
    "\n",
    "api.upload_folder(\n",
    "    folder_path=\"tourism_project/data\",\n",
    "    repo_id=repo_id,\n",
    "    repo_type=repo_type,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WxXiD9ZXxodF"
   },
   "source": [
    "Once the **data** folder created after executing the above cell, please upload the **tourism.csv** in to the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hh2TjRG5WJ4Z"
   },
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "SEG3M03Y9dn7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/model_building/prep.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/model_building/prep.py\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from huggingface_hub import HfApi\n",
    "\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "DATASET_PATH = \"hf://datasets/Retheesh/tourism_package_prediction/tourism.csv\"\n",
    "df = pd.read_csv(DATASET_PATH)\n",
    "print(\"Dataset loaded successfully.\")\n",
    "\n",
    "# Data preprocessing\n",
    "# Handle missing values\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['MonthlyIncome'].fillna(df['MonthlyIncome'].median(), inplace=True)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_columns = ['TypeofContact', 'Occupation', 'Gender', 'MaritalStatus', 'Designation', 'ProductPitched']\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Define target variable\n",
    "target_col = 'ProdTaken'\n",
    "\n",
    "# Split into X (features) and y (target)\n",
    "X = df.drop(columns=[target_col, 'CustomerID'])\n",
    "y = df[target_col]\n",
    "\n",
    "# Perform train-test split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "Xtrain.to_csv(\"Xtrain.csv\", index=False)\n",
    "Xtest.to_csv(\"Xtest.csv\", index=False)\n",
    "ytrain.to_csv(\"ytrain.csv\", index=False)\n",
    "ytest.to_csv(\"ytest.csv\", index=False)\n",
    "\n",
    "files = [\"Xtrain.csv\", \"Xtest.csv\", \"ytrain.csv\", \"ytest.csv\"]\n",
    "\n",
    "for file_path in files:\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=file_path,\n",
    "        path_in_repo=file_path.split(\"/\")[-1],\n",
    "        repo_id=\"Retheesh/tourism_package_prediction\",\n",
    "        repo_type=\"dataset\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eZZKnLkLjeM4"
   },
   "source": [
    "## Model Training and Registration with Experimentation Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "1CVFi1x89gkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/model_building/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/model_building/train.py\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import joblib\n",
    "import os\n",
    "from huggingface_hub import HfApi, create_repo\n",
    "from huggingface_hub.utils import RepositoryNotFoundError\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_tracking_uri(\"http://localhost:5000\")\n",
    "mlflow.set_experiment(\"tourism-customer-prediction-experiment\")\n",
    "\n",
    "api = HfApi()\n",
    "\n",
    "Xtrain_path = \"hf://datasets/Retheesh/tourism_package_prediction/Xtrain.csv\"\n",
    "Xtest_path = \"hf://datasets/Retheesh/tourism_package_prediction/Xtest.csv\"\n",
    "ytrain_path = \"hf://datasets/Retheesh/tourism_package_prediction/ytrain.csv\"\n",
    "ytest_path = \"hf://datasets/Retheesh/tourism_package_prediction/ytest.csv\"\n",
    "\n",
    "Xtrain = pd.read_csv(Xtrain_path)\n",
    "Xtest = pd.read_csv(Xtest_path)\n",
    "ytrain = pd.read_csv(ytrain_path).squeeze()\n",
    "ytest = pd.read_csv(ytest_path).squeeze()\n",
    "\n",
    "# Define numeric and categorical features\n",
    "numeric_features = [\n",
    "    'Age', 'NumberOfPersonVisiting', 'PreferredPropertyStar', \n",
    "    'NumberOfTrips', 'NumberOfChildrenVisiting', 'MonthlyIncome',\n",
    "    'NumberOfFollowups', 'DurationOfPitch'\n",
    "]\n",
    "\n",
    "categorical_features = [\n",
    "    'TypeofContact', 'CityTier', 'Occupation', 'Gender', \n",
    "    'MaritalStatus', 'Passport', 'OwnCar', 'Designation', \n",
    "    'PitchSatisfactionScore', 'ProductPitched'\n",
    "]\n",
    "\n",
    "# Preprocessor\n",
    "preprocessor = make_column_transformer(\n",
    "    (StandardScaler(), numeric_features),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    ")\n",
    "\n",
    "# Define Random Forest Classifier\n",
    "rf_model = RandomForestClassifier(random_state=42, n_jobs=-1)\n",
    "\n",
    "# Hyperparameter grid\n",
    "param_grid = {\n",
    "    'randomforestclassifier__n_estimators': [100, 200],\n",
    "    'randomforestclassifier__max_depth': [10, 20, None],\n",
    "    'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Pipeline\n",
    "model_pipeline = make_pipeline(preprocessor, rf_model)\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Grid Search\n",
    "    grid_search = GridSearchCV(model_pipeline, param_grid, cv=5, n_jobs=-1, scoring='roc_auc')\n",
    "    grid_search.fit(Xtrain, ytrain)\n",
    "\n",
    "    # Log parameter sets\n",
    "    results = grid_search.cv_results_\n",
    "    for i in range(len(results['params'])):\n",
    "        param_set = results['params'][i]\n",
    "        mean_score = results['mean_test_score'][i]\n",
    "\n",
    "        with mlflow.start_run(nested=True):\n",
    "            mlflow.log_params(param_set)\n",
    "            mlflow.log_metric(\"mean_roc_auc\", mean_score)\n",
    "\n",
    "    # Best model\n",
    "    mlflow.log_params(grid_search.best_params_)\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Predictions\n",
    "    y_pred_train = best_model.predict(Xtrain)\n",
    "    y_pred_test = best_model.predict(Xtest)\n",
    "    y_pred_proba_test = best_model.predict_proba(Xtest)[:, 1]\n",
    "\n",
    "    # Metrics\n",
    "    train_accuracy = accuracy_score(ytrain, y_pred_train)\n",
    "    test_accuracy = accuracy_score(ytest, y_pred_test)\n",
    "    \n",
    "    train_precision = precision_score(ytrain, y_pred_train)\n",
    "    test_precision = precision_score(ytest, y_pred_test)\n",
    "    \n",
    "    train_recall = recall_score(ytrain, y_pred_train)\n",
    "    test_recall = recall_score(ytest, y_pred_test)\n",
    "    \n",
    "    train_f1 = f1_score(ytrain, y_pred_train)\n",
    "    test_f1 = f1_score(ytest, y_pred_test)\n",
    "    \n",
    "    test_roc_auc = roc_auc_score(ytest, y_pred_proba_test)\n",
    "\n",
    "    # Log metrics\n",
    "    mlflow.log_metrics({\n",
    "        \"train_accuracy\": train_accuracy,\n",
    "        \"test_accuracy\": test_accuracy,\n",
    "        \"train_precision\": train_precision,\n",
    "        \"test_precision\": test_precision,\n",
    "        \"train_recall\": train_recall,\n",
    "        \"test_recall\": test_recall,\n",
    "        \"train_f1\": train_f1,\n",
    "        \"test_f1\": test_f1,\n",
    "        \"test_roc_auc\": test_roc_auc\n",
    "    })\n",
    "\n",
    "    # Save the model locally\n",
    "    model_path = \"tourism_customer_prediction_model.joblib\"\n",
    "    joblib.dump(best_model, model_path)\n",
    "\n",
    "    # Log the model artifact\n",
    "    mlflow.log_artifact(model_path, artifact_path=\"model\")\n",
    "    print(f\"Model saved as artifact at: {model_path}\")\n",
    "\n",
    "    # Upload to Hugging Face\n",
    "    repo_id = \"Retheesh/tourism-customer-prediction-model\"\n",
    "    repo_type = \"model\"\n",
    "\n",
    "    # Step 1: Check if the space exists\n",
    "    try:\n",
    "        api.repo_info(repo_id=repo_id, repo_type=repo_type)\n",
    "        print(f\"Space '{repo_id}' already exists. Using it.\")\n",
    "    except RepositoryNotFoundError:\n",
    "        print(f\"Space '{repo_id}' not found. Creating new space...\")\n",
    "        create_repo(repo_id=repo_id, repo_type=repo_type, private=False)\n",
    "        print(f\"Space '{repo_id}' created.\")\n",
    "\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=\"tourism_customer_prediction_model.joblib\",\n",
    "        path_in_repo=\"tourism_customer_prediction_model.joblib\",\n",
    "        repo_id=repo_id,\n",
    "        repo_type=repo_type,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0McYCZzkji5I"
   },
   "source": [
    "# Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9QrY2v77vbEZ"
   },
   "source": [
    "## Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "0-AMAI72CR-T"
   },
   "outputs": [],
   "source": [
    "os.makedirs(\"tourism_project/deployment\", exist_ok=True)\n",
    "os.makedirs(\"tourism_project/hosting\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZTicTDnPCVZr",
    "outputId": "c63b4416-aa75-46cb-e6b2-3edb3aecbc78"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/deployment/Dockerfile\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/deployment/Dockerfile\n",
    "# Use a minimal base image with Python 3.9 installed\n",
    "FROM python:3.9\n",
    "\n",
    "# Set the working directory inside the container to /app\n",
    "WORKDIR /app\n",
    "\n",
    "# Copy all files from the current directory on the host to the container's /app directory\n",
    "COPY . .\n",
    "\n",
    "# Install Python dependencies listed in requirements.txt\n",
    "RUN pip3 install -r requirements.txt\n",
    "\n",
    "RUN useradd -m -u 1000 user\n",
    "USER user\n",
    "ENV HOME=/home/user \\\n",
    "\tPATH=/home/user/.local/bin:$PATH\n",
    "\n",
    "WORKDIR $HOME/app\n",
    "\n",
    "COPY --chown=user . $HOME/app\n",
    "\n",
    "# Define the command to run the Streamlit app on port \"8501\" and make it accessible externally\n",
    "CMD [\"streamlit\", \"run\", \"app.py\", \"--server.port=8501\", \"--server.address=0.0.0.0\", \"--server.enableXsrfProtection=false\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LCvrklrBwNvJ"
   },
   "source": [
    "## Streamlit App"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXWe6ObRjP6-"
   },
   "source": [
    "Please ensure that the web app script is named `app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "WBG-jxM89jdp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/deployment/app.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/deployment/app.py\n",
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from huggingface_hub import hf_hub_download\n",
    "import joblib\n",
    "\n",
    "# Download and load the trained model\n",
    "model_path = hf_hub_download(repo_id=\"Retheesh/tourism-customer-prediction-model\", filename=\"tourism_customer_prediction_model.joblib\")\n",
    "model = joblib.load(model_path)\n",
    "\n",
    "# Streamlit UI\n",
    "st.title(\"Wellness Tourism Package Purchase Prediction\")\n",
    "st.write(\"\"\"\n",
    "This application predicts whether a customer will purchase the Wellness Tourism Package\n",
    "based on their characteristics and interaction data.\n",
    "Please enter the customer details below to get a prediction.\n",
    "\"\"\")\n",
    "\n",
    "# Create two columns for better layout\n",
    "col1, col2 = st.columns(2)\n",
    "\n",
    "with col1:\n",
    "    st.subheader(\"Customer Details\")\n",
    "    age = st.number_input(\"Age\", min_value=18, max_value=100, value=35)\n",
    "    typeof_contact = st.selectbox(\"Type of Contact\", [\"Company Invited\", \"Self Inquiry\"])\n",
    "    city_tier = st.selectbox(\"City Tier\", [1, 2, 3])\n",
    "    occupation = st.selectbox(\"Occupation\", [\"Salaried\", \"Small Business\", \"Large Business\", \"Free Lancer\"])\n",
    "    gender = st.selectbox(\"Gender\", [\"Male\", \"Female\"])\n",
    "    num_persons_visiting = st.number_input(\"Number of Persons Visiting\", min_value=1, max_value=10, value=2)\n",
    "    preferred_property_star = st.number_input(\"Preferred Property Star\", min_value=1, max_value=5, value=3)\n",
    "    marital_status = st.selectbox(\"Marital Status\", [\"Single\", \"Married\", \"Divorced\"])\n",
    "    num_trips = st.number_input(\"Number of Trips per Year\", min_value=0, max_value=20, value=1)\n",
    "\n",
    "with col2:\n",
    "    st.subheader(\"Additional Information\")\n",
    "    passport = st.selectbox(\"Has Passport\", [0, 1])\n",
    "    own_car = st.selectbox(\"Owns Car\", [0, 1])\n",
    "    num_children_visiting = st.number_input(\"Number of Children Visiting\", min_value=0, max_value=5, value=0)\n",
    "    designation = st.selectbox(\"Designation\", [\"Executive\", \"Manager\", \"Senior Manager\", \"AVP\", \"VP\"])\n",
    "    monthly_income = st.number_input(\"Monthly Income (USD)\", min_value=0, max_value=50000, value=15000)\n",
    "    \n",
    "    st.subheader(\"Interaction Details\")\n",
    "    pitch_satisfaction = st.slider(\"Pitch Satisfaction Score\", 1, 5, 3)\n",
    "    product_pitched = st.selectbox(\"Product Pitched\", [\"Basic\", \"Deluxe\", \"Standard\", \"Super Deluxe\", \"King\"])\n",
    "    num_followups = st.number_input(\"Number of Follow-ups\", min_value=0, max_value=10, value=3)\n",
    "    duration_pitch = st.number_input(\"Duration of Pitch (minutes)\", min_value=1, max_value=60, value=10)\n",
    "\n",
    "# Mapping for categorical variables\n",
    "contact_mapping = {\"Company Invited\": 0, \"Self Inquiry\": 1}\n",
    "occupation_mapping = {\"Salaried\": 0, \"Small Business\": 1, \"Large Business\": 2, \"Free Lancer\": 3}\n",
    "gender_mapping = {\"Male\": 0, \"Female\": 1}\n",
    "marital_mapping = {\"Single\": 0, \"Married\": 1, \"Divorced\": 2}\n",
    "designation_mapping = {\"Executive\": 0, \"Manager\": 1, \"Senior Manager\": 2, \"AVP\": 3, \"VP\": 4}\n",
    "product_mapping = {\"Basic\": 0, \"Deluxe\": 1, \"Standard\": 2, \"Super Deluxe\": 3, \"King\": 4}\n",
    "\n",
    "# Assemble input into DataFrame\n",
    "input_data = pd.DataFrame([{\n",
    "    'Age': age,\n",
    "    'TypeofContact': contact_mapping[typeof_contact],\n",
    "    'CityTier': city_tier,\n",
    "    'Occupation': occupation_mapping[occupation],\n",
    "    'Gender': gender_mapping[gender],\n",
    "    'NumberOfPersonVisiting': num_persons_visiting,\n",
    "    'PreferredPropertyStar': preferred_property_star,\n",
    "    'MaritalStatus': marital_mapping[marital_status],\n",
    "    'NumberOfTrips': num_trips,\n",
    "    'Passport': passport,\n",
    "    'OwnCar': own_car,\n",
    "    'NumberOfChildrenVisiting': num_children_visiting,\n",
    "    'Designation': designation_mapping[designation],\n",
    "    'MonthlyIncome': monthly_income,\n",
    "    'PitchSatisfactionScore': pitch_satisfaction,\n",
    "    'ProductPitched': product_mapping[product_pitched],\n",
    "    'NumberOfFollowups': num_followups,\n",
    "    'DurationOfPitch': duration_pitch\n",
    "}])\n",
    "\n",
    "# Predict button\n",
    "if st.button(\"Predict Purchase Probability\"):\n",
    "    prediction_proba = model.predict_proba(input_data)[0][1]\n",
    "    prediction = model.predict(input_data)[0]\n",
    "    \n",
    "    st.subheader(\"Prediction Result:\")\n",
    "    \n",
    "    if prediction == 1:\n",
    "        st.success(f\"Great!! This customer is LIKELY to purchase the Wellness Tourism Package\")\n",
    "        st.info(f\"Purchase Probability: {prediction_proba:.2%}\")\n",
    "    else:\n",
    "        st.warning(f\"Am skeptic that this customer will purchase the Wellness Tourism Package\")\n",
    "        st.info(f\"Purchase Probability: {prediction_proba:.2%}\")\n",
    "    \n",
    "    # Show confidence level\n",
    "    confidence = \"High\" if prediction_proba > 0.7 else \"Medium\" if prediction_proba > 0.5 else \"Low\"\n",
    "    st.write(f\"**Confidence Level:** {confidence}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07cYzWcIwTL-"
   },
   "source": [
    "## Dependency Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JEgfHL64jU7o"
   },
   "source": [
    "Please ensure that the dependency handling file is named `requirements.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "nvdmy7Wd9lda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/deployment/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/deployment/requirements.txt\n",
    "pandas==2.2.2\n",
    "huggingface_hub==0.32.6\n",
    "streamlit==1.43.2\n",
    "joblib==1.5.1\n",
    "scikit-learn==1.6.0\n",
    "mlflow==3.0.1\n",
    "numpy==2.1.3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4ynzpKNwWS_"
   },
   "source": [
    "# Hosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7p5sBvTg9nCW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tourism_project/hosting/hosting.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tourism_project/hosting/hosting.py\n",
    "from huggingface_hub import HfApi\n",
    "import os\n",
    "\n",
    "api = HfApi(token=os.getenv(\"HF_TOKEN\"))\n",
    "api.upload_folder(\n",
    "    folder_path=\"tourism_project/deployment\",\n",
    "    repo_id=\"Retheesh/tourism-package-prediction\",\n",
    "    repo_type=\"space\",\n",
    "    path_in_repo=\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PuCgAW2hktli"
   },
   "source": [
    "# MLOps Pipeline with Github Actions Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L5BZr5i8PKVN"
   },
   "source": [
    "**Note:**\n",
    "\n",
    "1. Before running the file below, make sure to add the HF_TOKEN to your GitHub secrets to enable authentication between GitHub and Hugging Face.\n",
    "2. The below code is for a sample YAML file that can be updated as required to meet the requirements of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J029tYPq4Rmq"
   },
   "source": [
    "```\n",
    "name: Tourism Project Pipeline\n",
    "\n",
    "on:\n",
    "  push:\n",
    "    branches:\n",
    "      - main  # Automatically triggers on push to the main branch\n",
    "\n",
    "jobs:\n",
    "\n",
    "  register-dataset:\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Install Dependencies\n",
    "        run: <add_code_here>\n",
    "      - name: Upload Dataset to Hugging Face Hub\n",
    "        env:\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "        run: <add_code_here>\n",
    "\n",
    "  data-prep:\n",
    "    needs: register-dataset\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Install Dependencies\n",
    "        run: <add_code_here>\n",
    "      - name: Run Data Preparation\n",
    "        env:\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "        run: <add_code_here>\n",
    "\n",
    "\n",
    "  model-traning:\n",
    "    needs: data-prep\n",
    "    runs-on: ubuntu-latest\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Install Dependencies\n",
    "        run: <add_code_here>\n",
    "      - name: Start MLflow Server\n",
    "        run: |\n",
    "          nohup mlflow ui --host 0.0.0.0 --port 5000 &  # Run MLflow UI in the background\n",
    "          sleep 5  # Wait for a moment to let the server starts\n",
    "      - name: Model Building\n",
    "        env:\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "        run: <add_code_here>\n",
    "\n",
    "\n",
    "  deploy-hosting:\n",
    "    runs-on: ubuntu-latest\n",
    "    needs: [model-traning,data-prep,register-dataset]\n",
    "    steps:\n",
    "      - uses: actions/checkout@v3\n",
    "      - name: Install Dependencies\n",
    "        run: <add_code_here>\n",
    "      - name: Push files to Frontend Hugging Face Space\n",
    "        env:\n",
    "          HF_TOKEN: ${{ secrets.HF_TOKEN }}\n",
    "        run: <add_code_here>\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T9fgZ_Mq3zzp"
   },
   "source": [
    "**Note:** To use this YAML file for our use case, we need to\n",
    "\n",
    "1. Go to the GitHub repository for the project\n",
    "2. Create a folder named ***.github/workflows/***\n",
    "3. In the above folder, create a file named ***pipeline.yml***\n",
    "4. Copy and paste the above content for the YAML file into the ***pipeline.yml*** file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvEUJ-t5kdxH"
   },
   "source": [
    "## Requirements file for the Github Actions Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nfqWcLRm-dga"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA6mP-Ebkm3O"
   },
   "source": [
    "## Github Authentication and Push Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T84Ei-g9Z2uw"
   },
   "source": [
    "* Before moving forward, we need to generate a secret token to push files directly from Colab to the GitHub repository.\n",
    "* Please follow the below instructions to create the GitHub token:\n",
    "    - Open your GitHub profile.\n",
    "    - Click on ***Settings***.\n",
    "    - Go to ***Developer Settings***.\n",
    "    - Expand the ***Personal access tokens*** section and select ***Tokens (classic)***.\n",
    "    - Click ***Generate new token***, then choose ***Generate new token (classic)***.\n",
    "    - Add a note and select all required scopes.\n",
    "    - Click ***Generate token***.\n",
    "    - Copy the generated token and store it safely in a notepad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KPDx4gqGh7cO"
   },
   "outputs": [],
   "source": [
    "# Install Git\n",
    "!apt-get install git\n",
    "\n",
    "# Set your Git identity (replace with your details)\n",
    "!git config --global user.email \"<-------GitHub Email Address------->\"\n",
    "!git config --global user.name \"<--------GitHub UserName--------->\"\n",
    "\n",
    "# Clone your GitHub repository\n",
    "!git clone https://github.com/<--------GitHub UserName--------->/<--------GitHub Reponame--------->.git\n",
    "\n",
    "# Move your folder to the repository directory\n",
    "!mv /content/tourism_project/ /content/<--------GitHub Reponame--------->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuUahCwVigon"
   },
   "outputs": [],
   "source": [
    "# Change directory to the cloned repository\n",
    "%cd <--------GitHub Reponame--------->/\n",
    "\n",
    "# Add the new folder to Git\n",
    "!git add .\n",
    "\n",
    "# Commit the changes\n",
    "!git commit -m \"first commit\"\n",
    "\n",
    "# Push to GitHub (you'll need your GitHub credentials; use a personal access token if 2FA enabled)\n",
    "!git push https://<--------GitHub UserName--------->:<--------GitHub Token--------->@github.com/<--------GitHub UserName--------->/<--------GitHub Reponame--------->.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-i8Jdyz-_L1"
   },
   "source": [
    "# Output Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTK8Bpda_UHg"
   },
   "source": [
    "- GitHub (link to repository, screenshot of folder structure and executed workflow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6qzzesaG_Xw8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3KDN31V2_YSr"
   },
   "source": [
    "- Streamlit on Hugging Face (link to HF space, screenshot of Streamlit app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NuIUdj3b_ZYV"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fN8j9-3nW8G9"
   },
   "source": [
    "<font size=6 color=\"navyblue\">Power Ahead!</font>\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "klg2JF-oBblG",
    "m0CcOjZ-BblL",
    "zm6bNQOJBblO",
    "z8C11AzTBblP",
    "0LbSu_p2jYfe",
    "9DtS3gNDjBbR",
    "hh2TjRG5WJ4Z",
    "eZZKnLkLjeM4",
    "0McYCZzkji5I",
    "9QrY2v77vbEZ",
    "LCvrklrBwNvJ",
    "07cYzWcIwTL-",
    "V4ynzpKNwWS_",
    "PuCgAW2hktli",
    "PvEUJ-t5kdxH",
    "BA6mP-Ebkm3O",
    "v-i8Jdyz-_L1"
   ],
   "provenance": []
  },
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "venev_enews",
   "language": "python",
   "name": "venev_enews"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   },
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
